# Open-Ended Questions

1. How does a Lakehouse combine the features of a data lake and a data warehouse?
2. What are the benefits of using a Lakehouse in Microsoft Fabric?
3. How can data be ingested into a Microsoft Fabric Lakehouse?
4. What role do shortcuts play in accessing data within a Lakehouse?
5. How can Power BI be used in conjunction with a Lakehouse?

# Mindmap

```
Microsoft Fabric Lakehouse
│
├── Introduction
│   ├── Lakehouse Definition
│   ├── OneLake Storage
│   └── Apache Spark and SQL Engines
│
├── Explore Lakehouse
│   ├── Delta Format Tables
│   ├── Schema-on-Read
│   ├── ACID Transactions
│   └── Analytics Tools
│
├── Microsoft Fabric Lakehouses
│   ├── Premium Tier Workspace
│   ├── Data Ingestion
│   ├── Data Factory Pipelines
│   ├── Dataflows (Gen2)
│   ├── Shortcuts
│   └── Lakehouse Explorer
│
├── Work with Lakehouses
│   ├── Create and Explore
│   ├── Semantic Model
│   ├── SQL Analytics Endpoint
│   ├── Ingest Data
│   ├── Access Data with Shortcuts
│   └── Data Governance
│
├── Explore and Transform Data
│   ├── Apache Spark
│   ├── Notebooks
│   ├── Spark Job Definitions
│   ├── SQL Analytic Endpoint
│   ├── Dataflows (Gen2)
│   └── Data Pipelines
│
└── Analyze and Visualize Data
    ├── Semantic Model
    ├── Power BI Reports
    └── End-to-End Analytics
```

# Practice Assessment

1. **Multiple Choice:**  
   What is the primary storage layer used in a Microsoft Fabric Lakehouse?  
   a) Azure Blob Storage  
   b) OneLake  
   c) Google Cloud Storage  
   d) Amazon S3  
   **Answer:** b) OneLake

2. **True/False:**  
   Lakehouses support predefined schemas only.  
   a) True  
   b) False  
   **Answer:** b) False

3. **Fill-in-the-Blanks:**  
   Lakehouses use _______ and _______ engines to process large-scale data.  
   (Options: Spark, SQL, Hadoop, NoSQL)  
   **Answer:** Spark, SQL

4. **Multiple Choice:**  
   Which tool is used for visual representation of transformations in Dataflows (Gen2)?  
   a) Jupyter Notebook  
   b) Power Query  
   c) Visual Studio  
   d) Tableau  
   **Answer:** b) Power Query

5. **True/False:**  
   Shortcuts allow data to be stored directly in the Lakehouse.  
   a) True  
   b) False  
   **Answer:** b) False

6. **Fill-in-the-Blanks:**  
   A Lakehouse's data is organized in a _______-on-read format.  
   (Options: schema, table, file, index)  
   **Answer:** schema

7. **Multiple Choice:**  
   What is the purpose of the SQL analytics endpoint in a Lakehouse?  
   a) To upload files  
   b) To query data using Transact-SQL  
   c) To create shortcuts  
   d) To manage user permissions  
   **Answer:** b) To query data using Transact-SQL

8. **True/False:**  
   Data Factory Pipelines can orchestrate Spark and Dataflow activities.  
   a) True  
   b) False  
   **Answer:** a) True

9. **Fill-in-the-Blanks:**  
   The semantic model in a Lakehouse is used to define a _______ model for your data.  
   (Options: relational, hierarchical, network, object)  
   **Answer:** relational

10. **Multiple Choice:**  
    Which of the following is NOT a method to ingest data into a Lakehouse?  
    a) Upload  
    b) Dataflows (Gen2)  
    c) SQL Server Management Studio  
    d) Notebooks  
    **Answer:** c) SQL Server Management Studio

# Complex Problem

**Scenario:**  
Your company is planning to implement a Microsoft Fabric Lakehouse to centralize its data analytics. The company has structured data from transactional systems and unstructured data from social media and website logs. The goal is to improve decision-making by analyzing data from multiple sources.

**Problem:**  
Design a data ingestion and transformation strategy for the Lakehouse. Consider the following:

- How will you ingest both structured and unstructured data?
- What tools and techniques will you use to transform the data?
- How will you ensure data consistency and integrity?
- How can you leverage Power BI for data visualization and reporting?

**Discussion Points:**

- Discuss the benefits and challenges of using Dataflows (Gen2) and Notebooks for data ingestion.
- Explore the role of schema-on-read in handling diverse data formats.
- Consider how ACID transactions can be utilized in maintaining data integrity.
- Evaluate the use of semantic models in Power BI for effective data visualization.